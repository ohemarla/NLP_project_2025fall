{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f17316",
   "metadata": {},
   "source": [
    "对预处理的中英文文本进行统计分析，包括计算在收集样本上英语字母和单词或汉字的概率和熵，并利用收集的英文文本验证齐夫定律(Zipf’s law)，分析过程中设置多个比例的文本量进行分析，其中针对10%、20%、50%和100%四个档位的文本量绘制相应的图片具体展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e324e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 库导入\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections as ct\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b0b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''分别为中文和英文设计不同的文本处理函数，对于中文直接对汉字进行相关的统计分析，而对于英文则分别进行字母和单词的统计分析，此外还有用于计算熵的函数。'''\n",
    "\n",
    "# 中文文本处理函数\n",
    "def zh_process(text):\n",
    "    character_counts = ct.Counter(text)\n",
    "    character_stats = pd.DataFrame(\n",
    "        character_counts.items(), \n",
    "        columns=['character', 'count']\n",
    "    )   # 构造一个DataFrame，包含汉字及其计数，df形式方便后续分析与作图\n",
    "    total_characters = character_stats['count'].sum()   # 统计总汉字数\n",
    "    character_stats['prob'] = character_stats['count'] / total_characters   # 计算每个汉字的概率\n",
    "    return character_stats, total_characters    # 返回包含汉字、计数、概率和熵的DataFrame以及语料总汉字数\n",
    "\n",
    "# 英文文本处理函数\n",
    "def en_process(text):\n",
    "    letter_counts = ct.Counter(c for c in text if c.isalpha())  # 统计字母\n",
    "    word_counts = ct.Counter(text.split())  # 统计单词\n",
    "    letter_stats = pd.DataFrame(\n",
    "        letter_counts.items(),\n",
    "        columns=['letter', 'count']\n",
    "    )\n",
    "    word_stats = pd.DataFrame(\n",
    "        word_counts.items(),\n",
    "        columns=['word', 'count']\n",
    "    )   # 分别构造字母和单词的DataFrame\n",
    "    total_letters = letter_stats['count'].sum()\n",
    "    total_words = word_stats['count'].sum()\n",
    "    letter_stats['prob'] = letter_stats['count'] / total_letters\n",
    "    word_stats['prob'] = word_stats['count'] / total_words\n",
    "    return letter_stats, word_stats, total_letters, total_words # 返回字母和单词的DataFrame及其总数\n",
    "\n",
    "# 熵函数  \n",
    "def calculate_entropy(dataframe):\n",
    "    entropy = sum(-p * np.log2(p) for p in dataframe['prob'] if p > 0)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6760a6",
   "metadata": {},
   "source": [
    "中文语料分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266a8ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 %\n",
      "828329\n",
      "9.79952493649018\n",
      "20 %\n",
      "1656658\n",
      "9.803411002287863\n",
      "30 %\n",
      "2484987\n",
      "9.809508135707087\n",
      "40 %\n",
      "3313316\n",
      "9.816796186353296\n",
      "50 %\n",
      "4141645\n",
      "9.822400841935904\n",
      "60 %\n",
      "4969974\n",
      "9.823540882222657\n",
      "70 %\n",
      "5798303\n",
      "9.829783104156189\n",
      "80 %\n",
      "6626632\n",
      "9.8283464107613\n",
      "90 %\n",
      "7454961\n",
      "9.826826556570781\n",
      "100 %\n",
      "8283290\n",
      "9.831362556659824\n"
     ]
    }
   ],
   "source": [
    "zh_file_path = 'zh_wikipedia.txt'   # 设置文件路径\n",
    "with open(zh_file_path, 'r', encoding='utf-8') as f:\n",
    "    zh_text = f.read()\n",
    "\n",
    "# 把语料分为按照10%、20%、30%、40%...100%进行分析\n",
    "zh_segments = [zh_text[:int(len(zh_text) * i / 10)] for i in range(1, 11)]\n",
    "\n",
    "# 构建多个DataFrame，用来存储不同文本量下的统计结果\n",
    "zh_stats_list = []\n",
    "zh_count_list = []\n",
    "zh_entropy_list = []\n",
    "\n",
    "# 利用循环，挨个进行分析，并储存下来处理的结果\n",
    "for i, segment in enumerate(zh_segments, 1):\n",
    "    print(10 * i, '%')\n",
    "    zh_stats, zh_count = zh_process(segment)\n",
    "    print(zh_count)\n",
    "    zh_entropy = calculate_entropy(zh_stats)\n",
    "    print(zh_entropy)\n",
    "\n",
    "    # 将当前结果添加到列表中\n",
    "    zh_stats_list.append(zh_stats)\n",
    "    zh_count_list.append(zh_count)\n",
    "    zh_entropy_list.append(zh_entropy)\n",
    "    \n",
    "zh_stats_total = zh_stats_list[-1]  # 获取完整文本的统计结果用于后续作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe02615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制汉字熵随文本量变化的图像\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.plot(range(1, 11), zh_entropy_list, marker='o')\n",
    "plt.title('汉字熵随文本量变化的图像', fontsize=16)\n",
    "plt.xlabel('文本量（%）', fontsize=14)\n",
    "plt.ylabel('汉字熵', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, entropy in enumerate(zh_entropy_list, 1):\n",
    "    plt.text(i, entropy, f'{entropy:.4f}', fontsize=10, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('zh_entropy_vs_text_size.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149fc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照出现次数排序汉字\n",
    "zh_stats = zh_stats.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "zh_stats.head(20)\n",
    "\n",
    "# 绘制汉字概率分布图（前20个汉字）\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "sns.barplot(x='character', y='prob', data=zh_stats.head(20))\n",
    "plt.title('全文本汉字出现概率分布图（前20个汉字）', fontsize=16)\n",
    "plt.xlabel('汉字', fontsize=14)\n",
    "plt.ylabel('概率', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, prob in enumerate(zh_stats['prob'].head(20), 1):\n",
    "    plt.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "#plt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig('zh_top20_char_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae75b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照出现次数排序汉字\n",
    "zh_stats_list[0] = zh_stats_list[0].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 绘制汉字概率分布图（前20个汉字）\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "sns.barplot(x='character', y='prob', data=zh_stats_list[0].head(20))\n",
    "plt.title('10%文本汉字出现概率分布图（前20个汉字）', fontsize=16)\n",
    "plt.xlabel('汉字', fontsize=14)\n",
    "plt.ylabel('概率', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, prob in enumerate(zh_stats_list[0]['prob'].head(20), 1):\n",
    "    plt.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "#plt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig('zh_top20_char_distribution10%.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5bfe553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照出现次数排序汉字\n",
    "zh_stats_list[1] = zh_stats_list[1].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 绘制汉字概率分布图（前20个汉字）\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "sns.barplot(x='character', y='prob', data=zh_stats_list[1].head(20))\n",
    "plt.title('20%全文本汉字出现概率分布图（前20个汉字）', fontsize=16)\n",
    "plt.xlabel('汉字', fontsize=14)\n",
    "plt.ylabel('概率', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, prob in enumerate(zh_stats_list[1]['prob'].head(20), 1):\n",
    "    plt.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "#plt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig('zh_top20_char_distribution20%.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27aeec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照出现次数排序汉字\n",
    "zh_stats_list[4] = zh_stats_list[4].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 绘制汉字概率分布图（前20个汉字）\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "sns.barplot(x='character', y='prob', data=zh_stats_list[4].head(20))\n",
    "plt.title('20%全文本汉字出现概率分布图（前20个汉字）', fontsize=16)\n",
    "plt.xlabel('汉字', fontsize=14)\n",
    "plt.ylabel('概率', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, prob in enumerate(zh_stats_list[4]['prob'].head(20), 1):\n",
    "    plt.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "#plt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig('zh_top20_char_distribution50%.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683402ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_stats_list[9] = zh_stats_list[9].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 绘制汉字的10%、20%、50%和100%文本量时候的四张前20汉字概率分布图，用矩阵图展示\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 13))\n",
    "# 设置子图标题\n",
    "titles = ['10%文本量', '20%文本量', '50%文本量', '全文本量']\n",
    "data_indices = [0, 1, 4, 9]\n",
    "for ax, title, idx in zip(axs.flatten(), titles, data_indices):\n",
    "    sns.barplot(x='character', y='prob', data=zh_stats_list[idx].head(20), ax=ax)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('汉字', fontsize=14)\n",
    "    ax.set_ylabel('概率', fontsize=14)\n",
    "    # 显示数值\n",
    "    for i, prob in enumerate(zh_stats_list[idx]['prob'].head(20), 1):\n",
    "        ax.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('zh_top20_char_distribution_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52eb370",
   "metadata": {},
   "source": [
    "英文语料分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60de5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 %\n",
      "843055\n",
      "10.83679149206672\n",
      "4.179617029079061\n",
      "20 %\n",
      "1686110\n",
      "10.916984726078098\n",
      "4.179684288289823\n",
      "30 %\n",
      "2529166\n",
      "10.95016877983413\n",
      "4.179268782280771\n",
      "40 %\n",
      "3372221\n",
      "10.98640578321347\n",
      "4.1800134784637475\n",
      "50 %\n",
      "4215277\n",
      "11.000954628015053\n",
      "4.179839196212444\n",
      "60 %\n",
      "5058332\n",
      "11.015494108718181\n",
      "4.179634874630656\n",
      "70 %\n",
      "5901387\n",
      "11.03180057591904\n",
      "4.179696978791808\n",
      "80 %\n",
      "6744443\n",
      "11.043846033057106\n",
      "4.179683136422841\n",
      "90 %\n",
      "7587498\n",
      "11.055347062882431\n",
      "4.179818009048096\n",
      "100 %\n",
      "8430554\n",
      "11.064286075640508\n",
      "4.179788158071513\n"
     ]
    }
   ],
   "source": [
    "en_file_path = 'en_wikipedia.txt'\n",
    "with open(en_file_path, 'r', encoding='utf-8') as f:\n",
    "    en_text_total = f.read()\n",
    "\n",
    "words = en_text_total.split()\n",
    "total_words = len(words)\n",
    "\n",
    "# 把语料分为按照10%、20%、30%、40%...100%的词量进行分析\n",
    "en_segments = [words[:int(len(words) * i / 10)] for i in range(1, 11)]\n",
    "\n",
    "# 构建多个DataFrame，用来存储不同文本量下的统计结果\n",
    "en_letter_stats_list = []\n",
    "en_word_stats_list = []\n",
    "en_letter_count_list = []\n",
    "en_word_count_list = []\n",
    "en_letter_entropy_list = []\n",
    "en_word_entropy_list = []\n",
    "\n",
    "# 利用循环，挨个进行分析，并储存下来处理的结果\n",
    "for i, segment in enumerate(en_segments, 1):\n",
    "    print(10 * i, '%')\n",
    "    segment_text = ' '.join(segment)\n",
    "    en_letter_stats, en_word_stats, en_letter_count, en_word_count = en_process(segment_text)\n",
    "    print(en_word_count)\n",
    "    en_word_entropy = calculate_entropy(en_word_stats)\n",
    "    print(en_word_entropy)\n",
    "    en_letter_entropy = calculate_entropy(en_letter_stats)\n",
    "    print(en_letter_entropy)\n",
    "\n",
    "    # 将当前结果添加到列表中\n",
    "    en_letter_stats_list.append(en_letter_stats)\n",
    "    en_word_stats_list.append(en_word_stats)\n",
    "    en_letter_count_list.append(en_letter_count)\n",
    "    en_word_count_list.append(en_word_count)\n",
    "    en_word_entropy_list.append(en_word_entropy)\n",
    "    en_letter_entropy_list.append(en_letter_entropy)\n",
    "\n",
    "en_word_stats_total = en_word_stats_list[-1]  # 获取完整文本的统计结果用于后续作图\n",
    "en_letter_stats_total = en_letter_stats_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d131e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制英文字母熵随文本量变化的图像\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.plot(np.arange(1, 11) * 10, en_letter_entropy_list, marker='o')\n",
    "plt.title('英文字母熵随文本量变化的图像', fontsize=16)\n",
    "plt.xlabel('文本量（%）', fontsize=14)\n",
    "plt.ylabel('英文字母熵', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, entropy in enumerate(en_letter_entropy_list, 1):\n",
    "    plt.text(i * 10, entropy, f'{entropy:.4f}', fontsize=10, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('en_letter_entropy_vs_text_size.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c71cfbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制英文单词熵随文本量变化的图像\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.plot(np.arange(1, 11) * 10, en_word_entropy_list, marker='o')\n",
    "plt.title('英文单词熵随文本量变化的图像', fontsize=16)\n",
    "plt.xlabel('文本量（%）', fontsize=14)\n",
    "plt.ylabel('英文单词熵', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, entropy in enumerate(en_word_entropy_list, 1):\n",
    "    plt.text(i * 10, entropy, f'{entropy:.4f}', fontsize=10, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('en_word_entropy_vs_text_size.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ed21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照出现次数排序字母\n",
    "en_letter_stats_total = en_letter_stats_total.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 绘图\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "sns.barplot(x='letter', y='prob', data=en_letter_stats_total)\n",
    "plt.title('英文字母出现概率分布图', fontsize=16)\n",
    "plt.xlabel('字母', fontsize=14)\n",
    "plt.ylabel('概率', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, prob in enumerate(en_letter_stats_total['prob'], 1):\n",
    "    plt.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('en_letter_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d85e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照出现次数排序单词\n",
    "en_word_stats_total = en_word_stats_total.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 绘图\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "sns.barplot(x='word', y='prob', data=en_word_stats_total.head(20))\n",
    "plt.title('英文单词出现概率分布图', fontsize=16)\n",
    "plt.xlabel('单词', fontsize=14)\n",
    "plt.ylabel('概率', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, prob in enumerate(en_word_stats_total.head(20)['prob'], 1):\n",
    "    plt.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('en_word_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55e0e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_letter_stats_list[0] = en_letter_stats_list[0].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "en_letter_stats_list[1] = en_letter_stats_list[1].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "en_letter_stats_list[4] = en_letter_stats_list[4].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "en_letter_stats_list[9] = en_letter_stats_list[9].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 绘制英文字母的10%、20%、50%和100%文本量时候的四张字母概率分布图，用矩阵图展示\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(22, 13))\n",
    "# 设置子图标题\n",
    "titles = ['10%文本量', '20%文本量', '50%文本量', '全文本量']\n",
    "data_indices = [0, 1, 4, 9]\n",
    "for ax, title, idx in zip(axs.flatten(), titles, data_indices):\n",
    "    sns.barplot(x='letter', y='prob', data=en_letter_stats_list[idx], ax=ax)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_xlabel('字母', fontsize=14)\n",
    "    ax.set_ylabel('概率', fontsize=14)\n",
    "    # 把坐标轴数值或者字母写大一点\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "    # 显示数值\n",
    "    for i, prob in enumerate(en_letter_stats_list[idx]['prob'], 1):\n",
    "        ax.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('en_letter_distribution_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "751b6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_word_stats_list[0] = en_word_stats_list[0].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "en_word_stats_list[1] = en_word_stats_list[1].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "en_word_stats_list[4] = en_word_stats_list[4].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "en_word_stats_list[9] = en_word_stats_list[9].sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 绘制英文单词的10%、20%、50%和100%文本量时候的四张排名前20单词概率分布图，用矩阵图展示\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(22, 13))\n",
    "# 设置子图标题\n",
    "titles = ['10%文本量', '20%文本量', '50%文本量', '全文本量']\n",
    "data_indices = [0, 1, 4, 9]\n",
    "for ax, title, idx in zip(axs.flatten(), titles, data_indices):\n",
    "    sns.barplot(x='word', y='prob', data=en_word_stats_list[idx].head(20), ax=ax)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_xlabel('单词', fontsize=14)\n",
    "    ax.set_ylabel('概率', fontsize=14)\n",
    "    # 把坐标轴数值或者字母写大一点\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "    # 显示数值\n",
    "    for i, prob in enumerate(en_word_stats_list[idx]['prob'].head(20), 1):\n",
    "        ax.text(i-1, prob, f'{prob:.4f}', fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('en_word_distribution_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2a0065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用单词验证zipf定律\n",
    "# 通过绘制log-log图散点图以及进行线性拟合来验证zipf定律\n",
    "\n",
    "rank = np.arange(1, len(en_word_stats_total) + 1)\n",
    "word_prob = en_word_stats_total['prob'].values\n",
    "log_rank = np.log(rank)\n",
    "log_prob = np.log(word_prob)\n",
    "\n",
    "# 绘制散点图\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "sns.scatterplot(x=log_rank, y=log_prob, edgecolor=None)\n",
    "\n",
    "plt.title('英文单词Zipf定律验证散点图(全文本量)', fontsize=16)\n",
    "plt.xlabel('log(排名)', fontsize=14)\n",
    "plt.ylabel('log(概率)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('en_word_zipf_scatter.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf2389a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.971</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.971</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>7.905e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 30 Oct 2025</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:06:37</td>     <th>  Log-Likelihood:    </th>  <td>  6484.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>240096</td>      <th>  AIC:               </th> <td>-1.297e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>240094</td>      <th>  BIC:               </th> <td>-1.295e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3638</td> <td>    0.005</td> <td>   66.190</td> <td> 0.000</td> <td>    0.353</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -1.3517</td> <td>    0.000</td> <td>-2811.571</td> <td> 0.000</td> <td>   -1.353</td> <td>   -1.351</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15551.559</td> <th>  Durbin-Watson:     </th> <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>22011.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.567</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.957</td>   <th>  Cond. No.          </th> <td>    132.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.971   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.971   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 7.905e+06   \\\\\n",
       "\\textbf{Date:}             & Thu, 30 Oct 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     16:06:37     & \\textbf{  Log-Likelihood:    } &    6484.9   \\\\\n",
       "\\textbf{No. Observations:} &      240096      & \\textbf{  AIC:               } & -1.297e+04  \\\\\n",
       "\\textbf{Df Residuals:}     &      240094      & \\textbf{  BIC:               } & -1.295e+04  \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.3638  &        0.005     &    66.190  &         0.000        &        0.353    &        0.375     \\\\\n",
       "\\textbf{x1}    &      -1.3517  &        0.000     & -2811.571  &         0.000        &       -1.353    &       -1.351     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 15551.559 & \\textbf{  Durbin-Watson:     } &     0.000  \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 22011.596  \\\\\n",
       "\\textbf{Skew:}          &   -0.567  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &    3.957  & \\textbf{  Cond. No.          } &      132.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.971\n",
       "Model:                            OLS   Adj. R-squared:                  0.971\n",
       "Method:                 Least Squares   F-statistic:                 7.905e+06\n",
       "Date:                Thu, 30 Oct 2025   Prob (F-statistic):               0.00\n",
       "Time:                        16:06:37   Log-Likelihood:                 6484.9\n",
       "No. Observations:              240096   AIC:                        -1.297e+04\n",
       "Df Residuals:                  240094   BIC:                        -1.295e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3638      0.005     66.190      0.000       0.353       0.375\n",
       "x1            -1.3517      0.000  -2811.571      0.000      -1.353      -1.351\n",
       "==============================================================================\n",
       "Omnibus:                    15551.559   Durbin-Watson:                   0.000\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22011.596\n",
       "Skew:                          -0.567   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.957   Cond. No.                         132.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(log_rank)\n",
    "y = log_prob\n",
    "model = sm.OLS(y,X)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78104228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  segment  n_words     slope  intercept  slope_se  slope_pvalue  r_squared\n",
      "0     10%    55146 -1.228702  -0.553216  0.000904           0.0   0.971038\n",
      "1     20%    85418 -1.278937  -0.169661  0.000742           0.0   0.972064\n",
      "2     30%   109715 -1.306087   0.040378  0.000666           0.0   0.972252\n",
      "3     40%   131832 -1.322507   0.172800  0.000616           0.0   0.972154\n",
      "4     50%   152693 -1.330072   0.220296  0.000581           0.0   0.971679\n",
      "5     60%   171788 -1.336260   0.260161  0.000552           0.0   0.971543\n",
      "6     70%   190066 -1.341306   0.295594  0.000528           0.0   0.971361\n",
      "7     80%   207991 -1.343995   0.308474  0.000510           0.0   0.970917\n",
      "8     90%   223866 -1.349238   0.349420  0.000495           0.0   0.970800\n",
      "9    100%   240096 -1.351668   0.363795  0.000481           0.0   0.970523\n"
     ]
    }
   ],
   "source": [
    "# 对 en_word_stats_list 的每个DataFrame做Zipf(log-log)线性拟合并汇总结果\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, df in enumerate(en_word_stats_list, start=1):\n",
    "    label = f\"{idx*10}%\"  # 10%,20%...\n",
    "    if df is None or df.empty:\n",
    "        results.append({\n",
    "            \"segment\": label, \"n_words\": 0,\n",
    "            \"slope\": np.nan, \"intercept\": np.nan,\n",
    "            \"slope_se\": np.nan, \"slope_pvalue\": np.nan,\n",
    "            \"r_squared\": np.nan\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    df_sorted = df.sort_values(by='prob', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    n = len(df_sorted)\n",
    "\n",
    "    # 计算排名和对数（natural log）\n",
    "    ranks = np.arange(1, n + 1)\n",
    "    probs = df_sorted['prob'].values\n",
    "    log_rank = np.log(ranks)\n",
    "    log_prob = np.log(probs)\n",
    "    X = sm.add_constant(log_rank)\n",
    "    model = sm.OLS(log_prob, X)\n",
    "    res = model.fit()\n",
    "\n",
    "    slope = res.params[1]\n",
    "    intercept = res.params[0]\n",
    "    slope_se = res.bse[1] if len(res.bse) > 1 else np.nan\n",
    "    slope_p = res.pvalues[1] if len(res.pvalues) > 1 else np.nan\n",
    "    r2 = res.rsquared\n",
    "\n",
    "    results.append({\n",
    "        \"segment\": label,\n",
    "        \"n_words\": n,\n",
    "        \"slope\": slope,\n",
    "        \"intercept\": intercept,\n",
    "        \"slope_se\": slope_se,\n",
    "        \"slope_pvalue\": slope_p,\n",
    "        \"r_squared\": r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "results_df.to_csv('zipf_fit_results_by_segment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c36c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制斜率随文本量增加的变化图\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.plot(np.arange(1, 11) * 10, results_df['slope'], marker='o')\n",
    "plt.title('拟合斜率随文本量变化图', fontsize=16)\n",
    "plt.xlabel('文本量（%）', fontsize=14)\n",
    "plt.ylabel('斜率', fontsize=14)\n",
    "\n",
    "# 显示数值\n",
    "for i, slope in enumerate(results_df['slope'], 1):\n",
    "    plt.text(i * 10, slope, f'{slope:.4f}', fontsize=10, ha='center', va='bottom')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('en_word_zipf_slope_vs_text_size.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fea764c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制R平方随文本量增加的变化图\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.plot(np.arange(1, 11) * 10, results_df['r_squared'], marker='o')\n",
    "plt.title('拟合R平方随文本量变化图', fontsize=16)\n",
    "plt.xlabel('文本量（%）', fontsize=14)\n",
    "plt.ylabel('R方', fontsize=14)\n",
    "# 显示数值\n",
    "for i, r2 in enumerate(results_df['r_squared'], 1):\n",
    "    plt.text(i * 10, r2, f'{r2:.4f}', fontsize=10, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('en_word_zipf_r2_vs_text_size.png', dpi=300, bbox_inches='tight')\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40f141bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制10%、20%、50%和100%文本量时候的四张英文单词Zipf定律验证散点图，用矩阵图展示\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 13))\n",
    "# 设置子图标题\n",
    "titles = ['10%文本量', '20%文本量', '50%文本量', '全文本量']\n",
    "data_indices = [0, 1, 4, 9]\n",
    "for ax, title, idx in zip(axs.flatten(), titles, data_indices):\n",
    "    rank = np.arange(1, len(en_word_stats_list[idx]) + 1)\n",
    "    word_prob = en_word_stats_list[idx]['prob'].values\n",
    "    log_rank = np.log(rank)\n",
    "    log_prob = np.log(word_prob)\n",
    "    sns.scatterplot(x=log_rank, y=log_prob, edgecolor=None, ax=ax)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_xlabel('log(排名)', fontsize=14)\n",
    "    ax.set_ylabel('log(概率)', fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('en_word_zipf_scatter_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
